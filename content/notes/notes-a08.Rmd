---
title: "Tidy Data and Pivoting"
output: 
  html_document:
    fig_caption: false
---

```{r, message=FALSE}
library(tidyverse)
```

## Learning Objectives 

From this topic, students are anticipated to be able to:

-   recognize whether a given dataset is 'tidy' or 'untidy'
-   understand why 'tidy' data is useful
-   reshape a dataset between a 'long' and 'wide' format, using `tidyr::pivot_longer()` and `tidyr::pivot_wider()`
-   deal with missing data in a tibble

## Resources

Video lecture for this topic:

-   [tidyr for Pivoting and Tidy Data](https://youtu.be/qivE6exNsZI)

Written resources on tidy data:

-   To learn how to use the `pivot_*()` functions, consult tidyr's [pivot vignette](https://tidyr.tidyverse.org/articles/pivot.html).

-   To get a better understanding of the concept of tidy data:

    -   Hadley Wickham's [paper on Tidy Data](https://vita.had.co.nz/papers/tidy-data.pdf) is the gold standard treatment of tidy data.
    -   A "code heavy" version of the tidy data paper is tidyr's ["Tidy Data" vignette](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html).

## Tidy Data and the Tidyverse 

In the last two weeks, we learned about the `dplyr` package for data manipulation and the `ggplot2` package for graphing. These two packages are part of the "tidyverse": a collection of data science packages that are designed to have input data frames and output data frames that are *tidy*. In fact, we can load all packages in the tidyverse at once with the single command `library(tidyverse)`. 

Here, we are using the word "tidy" in a technical sense - we're not talking about how "neat" or "organized" your data is. Instead, "tidy" is a very specific set of rules for storing data. 

```{r, fig.alt="Stylized text providing an overview of Tidy Data. The top reads \"Tidy data is a standard way of mapping the meaning of a dataset to its structure. - Hadley Wickham.\" On the left reads \"In tidy data: each variable forms a column; each observation forms a row; each cell is a single measurement.\" There is an example table on the lower right with columns \'id\', \'name\' and 'color' with observations for different cats, illustrating tidy data structure.", out.width="90%", echo=FALSE}

knitr::include_graphics("https://www.openscapes.org/img/blog/tidydata/tidydata_1.jpg")
```

(Image attribution: "[Tidy Data for reproducibility, efficiency, and collaboration](https://www.openscapes.org/blog/2020/10/12/tidy-data/)" by [Julia Lowndes](https://jules32.github.io/) and [Allison Horst](https://www.allisonhorst.com/).)


---

## Your turn: work with some untidy data 

All of the data we used before this week were already tidy. This made it easy to use the tidyverse packages `dplyr` and `ggplot2` to do what we needed to do. What happens when that's not the case? 

The `fivethirtyeight` R package contains a dataset called `drinks`. This dataset was compiled as part of a [FiveThirtyEight article](https://fivethirtyeight.com/features/dear-mona-followup-where-do-people-drink-the-most-beer-wine-and-spirits/) that explored (among other things) which countries consumes the most alcohol.

```{r, message=FALSE}
library(fivethirtyeight)

drinks_tbl1 <- as_tibble(drinks)
head(drinks_tbl1)
```

The following graphic was made from the `drinks` dataset.

```{r, message=FALSE, echo=FALSE}
drinks_tbl2 <- drinks_tbl1 %>% select(!total_litres_of_pure_alcohol) %>% pivot_longer(cols=ends_with("_servings"), names_to = "Alcohol", names_pattern = "(.*)_servings", values_to="Servings") %>% 
mutate(Alcohol=str_to_title(Alcohol))

drinks_tbl2 %>% ggplot(aes(x=Servings)) + geom_histogram() + facet_wrap(vars(Alcohol)) + ylab("Number of countries in each alcohol consumption group") + 
  xlab("Number of servings of alcohol consumed in 2010")
```

With a partner or a small group: 

1. Is it possible to reproduce the plots above using `drinks_tbl1` and *only* the `dplyr` and `ggplot2` packages? 
2. What is tidy format here? Mentally (or with pen and paper, or even with a spreadsheet editor like Excel or Google Sheets) sketch out the format of the tidy tibble. 
3. How would you reproduce the plots above using the `ggplot2` packages, given the data set in tidy format? 
4. Does it take a lot of code and effort to carry out the reproduction? 

Too easy? Then discuss the steps for how you would transform the first few rows of `drinks_tbl1` from untidy to tidy "by hand", i.e. not by using the tools from the `tidyr` package that we will learn about this week.    

--- 

## Tidy depends on the data analysis plan 

> "You better think (think) about what you're trying to do ..." - Aretha Franklin, "Think"

It's clear from the definition that tidiness is an attribute of a dataset. But did you know that tidiness also depends on what you are planning to *do* with the data? That's because what's an observation and what's a variable depends on the data analysis plan! 

We will demonstrate using data from "The Great British Bake Off" compiled by [Allison Hill](https://www.apreshill.com/) in the R package `bakeoff`. The graphics that follow (and the code to produce the graphics) were lightly adapted from Allison's [Plot Twist talk](https://www.apreshill.com/talk/2019-rladies-sydney/). 

Here is a bar plot of the number of viewers in millions within a 7-day window per episode, coloured by series.

```{r} 
library(bakeoff)

ratings_tbl1 <- ratings %>% 
  mutate(ep_id = row_number()) %>% 
  select(ep_id, viewers_7day, series, episode) 

# create coordinates for labels
series_labels <- ratings_tbl1 %>% 
  mutate(series=as.factor(series)) %>% 
  group_by(series) %>% 
  summarize(y_position = median(viewers_7day) + 1,
            x_position = mean(ep_id))

# make the plot
ratings_tbl1 %>% mutate(series=as.factor(series)) %>% 
ggplot(aes(x = ep_id, y = viewers_7day, fill = series)) +
  geom_col(alpha = .9) + 
  ggtitle("7-Day Viewership across Series 1-10") +
  geom_text(data = series_labels, aes(label = series,
                                      x = x_position, 
                                      y = y_position)) +
  theme_classic() +  
  scale_fill_manual(values = bakeoff_palette(), 
                    guide = "none") +
  xlab("Episode Number") + 
  ylab("7-Day Viewership (millions)")
```

This bar plot was constructed with the following tidy data representation:

```{r, echo=FALSE} 
head(ratings_tbl1)
```

Every row is an observation (a unique episode), and the columns are variables (episode number across series, 7-day viewership, series, and episode number within series).

### Your turn: what's tidy for a different plot? 

Here is another bar plot displaying percentage increase in the number of viewers in millions within a 7-day window from the premiere episode to finale episode for the first 10 series, based on the tidy tibble `ratings_tbl2`. 

```{r, echo = FALSE}
ratings_tbl2 <- ratings_tbl1 %>% mutate(series=as.factor(series)) %>% 
  group_by(series) %>% filter(episode == 1 | episode == max(episode)) %>% ungroup() %>% mutate(episode = recode(episode, `1` = "first", .default = "last")) %>% pivot_wider(id_cols=series, names_from=episode, values_from=viewers_7day)
```

```{r} 
ratings_tbl2 %>% mutate(pct_change = (last - first)/first) %>% 
  ggplot(aes(x = fct_rev(series), y=pct_change)) + 
  geom_col(fill = bakeoff::bakeoff_colors("baltic"), alpha = .5) + 
  labs(x = "Series", y = "% Increase in Viewers, First to Last Episode") +
  ggtitle("% Increase in Viewers from Premiere to Finale") + 
  scale_y_continuous(labels = scales::percent) +
  theme_classic() + 
  coord_flip() 
```

With a partner or a small group: 

1. What do you think `ratings_tbl2` looks like? 
2. Why is it tidy? 
3. Could you have calculated the information in `ratings_tbl2` using `ratings_tbl1`? (No need to write code - just discuss whether it's possible.) 

## Pivoting for Tidying

The `tidyr` package is loaded with the `tidyverse` and provides functions for pivoting data.  It has two main "pivoting" type functions: 

1. `pivot_longer()` makes datasets *longer* by increasing the number of rows and decreasing the number of columns. 
2.  `pivot_wider()` makes datasets *wider* by decreasing the number of rows and increasing the number of columns.

By now, you should have a sense for why this might be useful for tidying! 

### Pivoting Wider

Here is some code to create a variable for whether an episode is the first or last episode of the season to `ratings_tbl1` and subset to only the data from the first and last episodes of each eason. 

```{r} 
ratings_tbl1 <- ratings_tbl1 %>% 
 group_by(series) %>% 
  filter(episode == 1 | episode == max(episode)) %>%
  ungroup() %>% 
  mutate(episode_fl = recode(episode, `1` = "first", .default = "last"))

head(ratings_tbl1)
```

This is not the same as `ratings_tbl2`. To get it there, we need to make it wider. This is because compared to `ratings_tbl1` has spread 
a single observation (a series) across multiple rows. 

We can solve this problem using `pivot_wider`, which needs three pieces of information. 

- What is a set of columns that uniquely identifies each observations? Put their names in the `id_cols` argument. 

-  What should the new columns be named? Put the name of the column you want to take the new variable names from in the `names_from` argument. 

- What values should the new columns contain? Put the name of the  column you want to take the values from to `values_from` in the `values_from` argument. 

Note that if you don't specify an `id_cols` argument, `pivot_wider` will assume that you want it to be every column except those in `names_from` and `values_from`. 

```{r} 
ratings_tbl2 <- ratings_tbl1 %>% 
  pivot_wider(id_cols = series, 
              names_from=episode_fl, values_from=viewers_7day)

head(ratings_tbl2)
```

### Pivoting Longer 

Here is a snippet of WHO data on the number of tuberculosis cases in different years in different countries. 

```{r} 
table4a
```

If we wanted to visualize tuberculosis cases over time by country, then this format is not tidy. We want every row to be an observation (measurements within a country and a year), and we want each column to be a variable, like the year, the case count, and the country name.  That is, `table4a` is too *short*: each row contains information about multiple observations.

We can solve this problem using `pivot_longer`, which needs three pieces of information. We are going to decrease the number of columns, so ... 

- Which are the offending columns that we want to combine? Put their names in the `cols` argument. 

- These column names are often important though - so we should save them as values in a column of our new data set. What should the name of that column be? Put it in the `names_to` argument. 

- What should we name the column in our new data set that contains the values in the offending columns of the old data set? Put it in the `values_to` argument. 

```{r} 
table4a %>% pivot_longer(c(`1999`, `2000`), 
                         names_to = "year", 
                         values_to = "cases")
```

## Separating and Uniting for Tidying

The `tidyr` package has a function for gluing columns together (`unite`) and for cutting columns apart (`separate`). Why might this help us tidy? Here is another snippet of WHO Tuberculosis data.

```{r} 
table3
```

The `rate` column contains the values of two variables: case counts and population counts. We would like to snip it apart at the "/" character to create two columns: 

```{r} 
(table5 <- table3 %>% separate(col = rate, 
                    into = c("cases", "population")))
```

The `col` argument specifies the column we want to separate, 
and the `into` argument specifies the names of the new columns. The `sep` argument (not specified here) specifies where we want to cut. The default is pretty clever - it separates at any non-alphanumeric value. (How this is accomplished involves *regular expressions*, which are very useful when working with character data. We will learn more about regular expressions in STAT 545B. )

## Your turn: learning to use tidyr

We think the best way to learn the basics of tidyr is to work through the first two parts of Worksheet A4. 

### First 30 minutes of Class 2

- Haven't attempted all of the questions on the first two parts of Worksheet A4? Then spend this time attempting unattempted questions. 
- Finished attempting all of the questions? Then do the optional [R4DS Tidying](https://r4ds.hadley.nz/data-tidy) reading, and maybe even do some of the exercises for extra practice. 

During this time, teaching team will also walk around and answer questions and chat about anything tidy related. 

### Next 50 min in Class 2

Now's your chance to ask about any questions you got stuck on and get them answered by the instructor! 

## Coda: Tidy and Data Ethics

> "Of course, it is very easy to disregard people you have never met, and who are certainly not your friends or family members. After all, in the eyes of an outsider, who is in no danger whatsoever, the people caught up in the situation are nothing more than simply statistics." - Andrew James Pritchard, "Not Collateral Damage"

The book ["Data Feminism"](https://data-feminism.mitpress.mit.edu/) by Catherine D'Ignazio and Lauren F. Klein "presents a new way of thinking about data science and data ethics that is informed by the ideas of intersectional feminism". Power is an important theme throughout the book: they point out that "data collection has long been employed as a technique of consolidating knowledge about the people whose data are collected, and therefore consolidating power over their lives." 

In Chapter 5, the authors make several points about cleaning and tidying data: 

- "Data do not need cleaning until there are strangers in the dataset ... Being a stranger in the dataset is not an inherently bad thing, but it carries significant risk of what renowned postcolonial scholar Gayatri Spivak calls *epistemic violence* - the harm that dominant groups like colonial powers wreak by privileging their ways of knowing over local and Indigenous ways." 

- Tidying data is a "lossy" process: "But what might be lost in the process of dominating and disciplining data? Whose perspectives might be lost in that process? And, conversely, whose perspectives might be additionally imposed?" 

- Further riffing on that point: "the process of cleaning and tidying data ... at times, can be a destructive rather than constructive act. One way to think of it is like chopping off the roots of a tree that connects it to the ground from which it grew. **Itâ€™s an act that irreversibly separates the data from their context.**"  

- Untidy data is not inherently "bad", and tidy data is not inherently "good": "The ideas expressed by Wickham, and by the press, carry the assumption that all data scientists, in all contexts, value cleanliness and control over messiness and complexity ... these are not the requirements, nor the goals, of all data projects." 

These are important points for us to reflect on as a data science community. 

## Attribution 

Most of these notes were compiled by Lucy Gao. The remainder was compiled by previous iterations of the instructional staff, including Vincenzo Coia. 

Albert Y. Kim inspired the in-class exercises using the `drinks` data set from `fivethirtyeight`. Allison Horst and Julia Lowndes created the illustrated tidy data series. Alison Hill inspired the Great British Bakeoff example. We are immensely grateful to these people for creating amazing educational materials!

We would also like to thank Samantha Tyner for pointing us towards the Data Feminism book during her week as the curator of the [\@WomenInStat](https://twitter.com/WomenInStat) Twitter account. 